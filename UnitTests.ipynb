{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "This notebook run unit tests on all models in the model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7bde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DeGirum PySDK\n",
    "import degirum as dg\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4388e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to ai server model zoo\n",
    "ai_server_address='localhost' #fill in the IP address of AI server. Use localhost if running locally\n",
    "zoo = dg.connect_model_zoo(ai_server_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40911319-a991-449a-93cc-5d5c24a6995f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name yolo_v5s_coco--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobiledet_coco--320x320_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_imagenet--224x224_float_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_generic_object--224x224_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_imagenet--224x224_float_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_lp_det--512x512_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_face_det--512x512_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_lp_ocr--256x256_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v1_imagenet--224x224_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_hand_det--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_face_det--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_hand_det--512x512_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_sign_language--224x224_float_n2x_cpu_1\n",
      "Success\n",
      "Model name efficientnet_em_imagenet--240x240_quant_n2x_orca_1\n",
      "Success\n",
      "Model name efficientdet_lite1_coco--384x384_quant_n2x_orca_1\n",
      "Success\n",
      "Model name resnet50_imagenet--224x224_pruned_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_lp_det--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v1_imagenet--224x224_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5m_coco--512x512_pruned_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v2_ssd_coco--300x300_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_coco--576x576_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_lp_ocr--256x256_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v2_imagenet--224x224_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name resnet50_imagenet--224x224_pruned_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_coco--512x512_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_person_det--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name efficientnet_em_imagenet--240x240_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name efficientdet_lite1_coco--384x384_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_household_objects--512x512_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobiledet_coco--320x320_quant_n2x_orca_1\n",
      "Success\n",
      "Model name efficientnet_es_imagenet--224x224_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_coco--576x576_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_imagenet--224x224_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v2_generic_object--224x224_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v2_ssd_generic_object--192x192_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1\n",
      "Success\n",
      "Model name mobilenet_v2_sign_language--224x224_float_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5m_coco--512x512_pruned_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name efficientnet_es_imagenet--224x224_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name yolo_v5s_household_objects--512x512_quant_n2x_cpu_1\n",
      "Success\n",
      "Model name mobilenet_v2_ssd_generic_object--192x192_quant_n2x_orca_1\n",
      "Success\n",
      "Model name yolo_v5s_person_det--512x512_quant_n2x_cpu_1\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "for index, filepath in enumerate(glob.iglob('UnitTestConfigs/*.json')):\n",
    "#     print(filepath)\n",
    "    config=open(filepath)\n",
    "    config_options=json.load(config)\n",
    "    config.close()\n",
    "    # load AI model \n",
    "    model_name=config_options['MODEL_PARAMETERS'][0]['ModelName']\n",
    "    if(model_name in zoo.list_models()):\n",
    "        model = zoo.load_model(model_name)\n",
    "        input_image_path=config_options['TEST_IMAGE'][0]['InputPath']\n",
    "        expected_results=config_options['RESULTS']\n",
    "        # perform AI model inference on given image file (assuming current direcory is where this notebook is located)\n",
    "        res = model(input_image_path)\n",
    "#         print('Model name', model_name)\n",
    "        if(expected_results==res.results):\n",
    "              print('Model name', model_name)\n",
    "              pass\n",
    "              print('Success')\n",
    "        else:\n",
    "#             pass\n",
    "            print('###################Failure################')\n",
    "            print('Model name', model_name)\n",
    "            print('###################Failure################')\n",
    "    else:\n",
    "        pass\n",
    "        print('**********************************************')\n",
    "        print('Model',model_name,' not found in the model zoo')\n",
    "        print('**********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78d32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='UnitTestConfigs/mobilenet_v2_sign_language--224x224_float_n2x_cpu_1.json'\n",
    "config=open(filepath)\n",
    "config_options=json.load(config)\n",
    "config.close()\n",
    "model_name=config_options['MODEL_PARAMETERS'][0]['ModelName']\n",
    "if(model_name in zoo.list_models()):\n",
    "    model = zoo.load_model(model_name)\n",
    "    input_image_path=config_options['TEST_IMAGE'][0]['InputPath']\n",
    "    expected_results=config_options['RESULTS']\n",
    "    # perform AI model inference on given image file (assuming current direcory is where this notebook is located)\n",
    "    res = model(input_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59673f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=zoo.load_model('mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303e6082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_pose_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1023bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category_id': 10, 'label': 'k', 'score': 0.9756968021392822},\n",
       " {'category_id': 7, 'label': 'h', 'score': 0.00982069130986929},\n",
       " {'category_id': 21, 'label': 'v', 'score': 0.008860746398568153},\n",
       " {'category_id': 22, 'label': 'w', 'score': 0.0047896504402160645},\n",
       " {'category_id': 17, 'label': 'r', 'score': 0.0004476014291867614}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89939619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category_id': 10, 'label': 'k', 'score': 0.9756960868835449},\n",
       " {'category_id': 7, 'label': 'h', 'score': 0.009821007028222084},\n",
       " {'category_id': 21, 'label': 'v', 'score': 0.008861111477017403},\n",
       " {'category_id': 22, 'label': 'w', 'score': 0.004789702594280243},\n",
       " {'category_id': 17, 'label': 'r', 'score': 0.00044762209290638566}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a06c5e24-63a4-411a-a0c9-372a279894be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image=Image.open('./images/TwoCats.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f591a87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category_id': 283, 'label': 'tiger cat', 'score': 0.10546875}, {'category_id': 282, 'label': 'tabby, tabby cat', 'score': 0.10546875}, {'category_id': 286, 'label': 'Egyptian cat', 'score': 0.078125}, {'category_id': 429, 'label': 'barrow, garden cart, lawn cart, wheelbarrow', 'score': 0.0234375}, {'category_id': 905, 'label': 'window screen', 'score': 0.015625}]\n"
     ]
    }
   ],
   "source": [
    "effnet_es=zoo.load_model('efficientnet_em_imagenet--240x240_quant_tflite_cpu_1')\n",
    "input_image_path='./images/TwoCats.bmp'\n",
    "predictions=effnet_es(input_image_path)\n",
    "print(predictions.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bdf7470-3fcc-4e6e-ac2b-0209d7acd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save('./images/TwoCats.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a67dd8e0-d6ca-4ff1-a112-2924705f517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientdet_lite1_coco--384x384_quant_n2x_cpu_1',\n",
       " 'efficientdet_lite1_coco--384x384_quant_n2x_orca_1',\n",
       " 'efficientdet_lite1_coco--384x384_quant_tflite_cpu_1',\n",
       " 'efficientnet_em_imagenet--240x240_quant_n2x_cpu_1',\n",
       " 'efficientnet_em_imagenet--240x240_quant_n2x_orca_1',\n",
       " 'efficientnet_em_imagenet--240x240_quant_tflite_cpu_1',\n",
       " 'efficientnet_es_imagenet--224x224_quant_n2x_cpu_1',\n",
       " 'efficientnet_es_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'efficientnet_es_imagenet--224x224_quant_tflite_cpu_1',\n",
       " 'mobiledet_coco--320x320_quant_n2x_cpu_1',\n",
       " 'mobiledet_coco--320x320_quant_n2x_orca_1',\n",
       " 'mobiledet_coco--320x320_quant_tflite_cpu_1',\n",
       " 'mobilenet_v1_imagenet--224x224_quant_n2x_cpu_1',\n",
       " 'mobilenet_v1_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_imagenet--224x224_quant_tflite_cpu_1',\n",
       " 'mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_cpu_1',\n",
       " 'mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_posenet_coco_keypoints--353x481_quant_tflite_cpu_1',\n",
       " 'mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_cpu_1',\n",
       " 'mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_yamnet_sound_cls--96x64_quant_tflite_cpu_1',\n",
       " 'mobilenet_v2_generic_object--224x224_quant_n2x_cpu_1',\n",
       " 'mobilenet_v2_generic_object--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_generic_object--224x224_quant_tflite_cpu_1',\n",
       " 'mobilenet_v2_imagenet--224x224_float_n2x_cpu_1',\n",
       " 'mobilenet_v2_imagenet--224x224_float_n2x_orca_1',\n",
       " 'mobilenet_v2_imagenet--224x224_float_tflite_cpu_1',\n",
       " 'mobilenet_v2_imagenet--224x224_quant_n2x_cpu_1',\n",
       " 'mobilenet_v2_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_imagenet--224x224_quant_tflite_cpu_1',\n",
       " 'mobilenet_v2_sign_language--224x224_float_n2x_cpu_1',\n",
       " 'mobilenet_v2_sign_language--224x224_float_n2x_orca_1',\n",
       " 'mobilenet_v2_sign_language--224x224_float_tflite_cpu_1',\n",
       " 'mobilenet_v2_ssd_coco--300x300_quant_n2x_cpu_1',\n",
       " 'mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_ssd_coco--300x300_quant_tflite_cpu_1',\n",
       " 'mobilenet_v2_ssd_generic_object--192x192_quant_n2x_cpu_1',\n",
       " 'mobilenet_v2_ssd_generic_object--192x192_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_ssd_generic_object--192x192_quant_tflite_cpu_1',\n",
       " 'resnet50_imagenet--224x224_pruned_quant_n2x_cpu_1',\n",
       " 'resnet50_imagenet--224x224_pruned_quant_n2x_orca_1',\n",
       " 'resnet50_imagenet--224x224_pruned_quant_tflite_cpu_1',\n",
       " 'yolo_v5m_coco--512x512_pruned_quant_n2x_cpu_1',\n",
       " 'yolo_v5m_coco--512x512_pruned_quant_n2x_orca_1',\n",
       " 'yolo_v5m_coco--512x512_pruned_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_coco--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_coco--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_coco--512x512_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_coco--576x576_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_coco--576x576_quant_n2x_orca_1',\n",
       " 'yolo_v5s_coco--576x576_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_face_det--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_face_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_face_det--512x512_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_hand_det--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_hand_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_hand_det--512x512_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_household_objects--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_household_objects--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_household_objects--512x512_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_lp_det--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_lp_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_lp_det--512x512_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_lp_ocr--256x256_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_lp_ocr--256x256_quant_n2x_orca_1',\n",
       " 'yolo_v5s_lp_ocr--256x256_quant_tflite_cpu_1',\n",
       " 'yolo_v5s_person_det--512x512_quant_n2x_cpu_1',\n",
       " 'yolo_v5s_person_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_person_det--512x512_quant_tflite_cpu_1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849e848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

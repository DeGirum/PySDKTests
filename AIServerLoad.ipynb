{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da8f424",
   "metadata": {},
   "source": [
    "This notebook provides an example of loading DeGirum AI server with inferences. \n",
    "\n",
    "Script runs multiple batch inferences in multiple threads and measures average frame processing time.\n",
    "\n",
    "You specify the following parameters:\n",
    " - the AI server hostname to use\n",
    " - the model name to use\n",
    " - the number of models (threads) runing in parallel\n",
    " - the number of frames to process\n",
    " - the image to run inferences on\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66fd1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# script global parameters\n",
    "#\n",
    "ai_server_address = None # fill in the IP address of AI server. Use localhost if running locally\n",
    "model_name = \"mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1\" # model name to use\n",
    "nmodels = 2 # number of models to run in parallel\n",
    "nbatch = 100 # number of frames to process\n",
    "img = \"./images/TwoCats.jpg\" # path to image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73810d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d35dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the AI server\n",
    "zoo = dg.connect_model_zoo(ai_server_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25919e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thread function which runs inferences in a batch, measures total inference duration, \n",
    "# and prints average frame inference time\n",
    "def one_batch(model, data, nbatch):\n",
    "    \n",
    "    def source():\n",
    "        for n in range(nbatch):\n",
    "            yield data            \n",
    "    \n",
    "    tstart = time.time_ns()\n",
    "    for res in model.predict_batch(source()):\n",
    "        pass\n",
    "    frame_time_ms = (time.time_ns() - tstart) * 1e-6 / nbatch\n",
    "    print(f\"Model #{model.n} average frame time: {frame_time_ms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b35403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "models = []\n",
    "for n in range(nmodels):\n",
    "    m = zoo.load_model(model_name)\n",
    "    m.n = n      \n",
    "    m._model_parameters.InputImgFmt = [\"JPEG\"]  # to save on network traffic, \n",
    "                                                # use JPEG data format when sending frames to AI server    \n",
    "    models.append(m)\n",
    "    \n",
    "# run model image pre-processor once to get raw bytes to be sent to the model;\n",
    "# this we do to skip pre-processing stage when running batch inference to minimize time variations\n",
    "data = models[0]._preprocessor.forward(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992ee7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #0 average frame time: 22.590663\n",
      "Model #1 average frame time: 22.665187999999997\n"
     ]
    }
   ],
   "source": [
    "# create threads\n",
    "threads = []\n",
    "for m in models:\n",
    "    t = threading.Thread(target=one_batch,args=(m, data, nbatch))\n",
    "    threads.append(t)\n",
    "    \n",
    "# start threads    \n",
    "for t in threads:\n",
    "    t.start()\n",
    "    \n",
    "# wait when all threads finish\n",
    "for t in threads:\n",
    "    t.join()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f2536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

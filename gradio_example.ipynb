{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c15cb24",
   "metadata": {},
   "source": [
    "This notebook is a simple example how to use DeGirum PySDK to do AI inference of a video stream from local camera.\n",
    "OpenCV is required to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import cv2 # OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd56bc5-6801-4d78-b661-7ca9b87a565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to default model zoo\n",
    "zoo = dg.connect_model_zoo('192.168.0.169')\n",
    "# load AI model 'ssd_mobilenet_v2' for DeGirum Orca AI accelerator\n",
    "model = zoo.load_model(\"mobilenet_v1_imagenet--224x224_quant_n2x_cpu_1\")\n",
    "\n",
    "# set model parameters\n",
    "model.image_backend = 'pil' # select OpenCV backend: needed to have overlay image in OpenCV format\n",
    "model.overlay_show_probabilities = True # show probabilities on overlay image\n",
    "model.overlay_font_scale=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71748f-7adb-4686-b21b-21e5e2b7777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_models=zoo.list_models(device='orca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0c5032-33a0-44c5-9dcd-4104d2f5f29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientdet_lite1_coco--384x384_quant_n2x_orca_1',\n",
       " 'efficientnet_em_imagenet--240x240_quant_n2x_orca_1',\n",
       " 'efficientnet_es_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'mobiledet_coco--320x320_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1',\n",
       " 'mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_generic_object--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_imagenet--224x224_float_n2x_orca_1',\n",
       " 'mobilenet_v2_imagenet--224x224_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_sign_language--224x224_float_n2x_orca_1',\n",
       " 'mobilenet_v2_ssd_coco--300x300_quant_n2x_orca_1',\n",
       " 'mobilenet_v2_ssd_generic_object--192x192_quant_n2x_orca_1',\n",
       " 'resnet50_imagenet--224x224_pruned_quant_n2x_orca_1',\n",
       " 'yolo_v5m_coco--512x512_pruned_quant_n2x_orca_1',\n",
       " 'yolo_v5s_coco--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_coco--576x576_quant_n2x_orca_1',\n",
       " 'yolo_v5s_face_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_hand_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_household_objects--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_lp_det--512x512_quant_n2x_orca_1',\n",
       " 'yolo_v5s_lp_ocr--256x256_quant_n2x_orca_1',\n",
       " 'yolo_v5s_person_det--512x512_quant_n2x_orca_1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7d408-9ca7-4c1a-bdff-a336c641b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model=zoo.load_model(\"mobilenet_v1_posenet_coco_keypoints--353x481_quant_n2x_orca_1\")\n",
    "pose_model.overlay_show_labels=False\n",
    "pose_model.overlay_show_labels = False\n",
    "pose_model.overlay_line_width = 2\n",
    "pose_model.overlay_alpha = 1\n",
    "pose_model.image_backend='pil'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b542737-f344-46a8-ac5a-27e87cabe816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenet(test_image):\n",
    "    poses=pose_model(test_image)\n",
    "    faces=model(test_image)\n",
    "    return poses.image_overlay, faces.image_overlay\n",
    "\n",
    "video_input=gr.inputs.Video(    source=\"webcam\", \n",
    "                                label=None, \n",
    "                                optional=False)\n",
    "image_input=gr.inputs.Image(    shape=None, \n",
    "                                image_mode=\"RGB\", \n",
    "                                invert_colors=False, \n",
    "                                source=\"upload\", \n",
    "                                tool=\"editor\", \n",
    "                                type=\"numpy\", \n",
    "                                label=None, \n",
    "                                optional=False)\n",
    "\n",
    "iface = gr.Interface(fn=posenet, inputs=video_input, outputs=[\"image\",\"image\"])\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717ed2f-7f03-43d3-97f0-a7f587b0ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenet(test_image,model_name):\n",
    "    model=zoo.load_model(model_name)\n",
    "    image_list=[test_image for i in range(0,1)]\n",
    "    for poses in model.predict_batch(image_list):\n",
    "        pass\n",
    "    return poses.image_overlay\n",
    "\n",
    "image_input=gr.inputs.Image(    shape=None, \n",
    "                                image_mode=\"RGB\", \n",
    "                                invert_colors=False, \n",
    "                                source=\"upload\", \n",
    "                                tool=\"editor\", \n",
    "                                type=\"numpy\", \n",
    "                                label=None, \n",
    "                                optional=False)\n",
    "model_name=gr.inputs.Dropdown(orca_models, type=\"value\", default=None, label=None, optional=False)\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=posenet, inputs=[image_input,model_name], outputs=[\"image\"])\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f0551-8706-41a9-b961-6cd765f4ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenet(test_image,model_name):\n",
    "    model=zoo.load_model(model_name)\n",
    "    image_list=[test_image for i in range(0,1)]\n",
    "    for poses in model.predict_batch(image_list):\n",
    "        pass\n",
    "    return poses\n",
    "\n",
    "image_input=gr.inputs.Image(    shape=None, \n",
    "                                image_mode=\"RGB\", \n",
    "                                invert_colors=False, \n",
    "                                source=\"upload\", \n",
    "                                tool=\"editor\", \n",
    "                                type=\"numpy\", \n",
    "                                label=None, \n",
    "                                optional=False)\n",
    "model_name=gr.inputs.Dropdown(orca_models, type=\"value\", default=None, label=None, optional=False)\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=posenet, inputs=[image_input,model_name], outputs=[\"textbox\"])\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f8486-b378-402e-9e6d-2f88f50b80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model.measure_time=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929ba43-b98a-4137-9df2-74580a116dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model.time_stats()['FrameTotalDuration_ms'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2733cb-b85b-461c-8d9c-575166909867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "model1 = zoo.load_model(\"mobilenet_v1_imagenet--224x224_quant_n2x_orca_1\")\n",
    "model2 = zoo.load_model(\"mobilenet_v2_imagenet--224x224_quant_n2x_orca_1\")\n",
    "\n",
    "gr.Parallel(model1, model2).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570d520-23b1-49e1-83ee-615c276bc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = cv2.VideoCapture(1)\n",
    "\n",
    "# define iterator function, which returns frames from camera \n",
    "def source():\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        yield frame\n",
    "\n",
    "# AI prediction loop\n",
    "# Press 'x' to stop\n",
    "for res in pose_model.predict_batch(source()):\n",
    "    cv2.imshow(\"AI camera\", res.image_overlay)\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('x'):\n",
    "        break\n",
    "        \n",
    "stream.release() # release camera stream\n",
    "cv2.destroyAllWindows() # close OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df660a27-01c2-4906-90dd-1ffd61061eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(inp):\n",
    "    print(model(inp).results)\n",
    "    return model(inp).results\n",
    "\n",
    "image = gr.inputs.Image(label=\"Input Image\", source=\"upload\")\n",
    "label = gr.outputs.Textbox()\n",
    "\n",
    "gr.Interface(fn=classify_image, inputs=image, outputs=label).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43e728-2915-400e-916a-17243322923a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2367c6-bda0-4673-a0c6-c98a9a90d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def snap(image):\n",
    "    return np.flipud(image)\n",
    "\n",
    "\n",
    "iface = gr.Interface(snap, gr.inputs.Video(source=\"webcam\"), \"image\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40324139-f07d-4139-9430-7a2cd81d9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model.input_numpy_colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932aefb1-5870-4b6e-9679-c528fbd112de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video stream from local camera #0\n",
    "stream = cv2.VideoCapture(1)\n",
    "\n",
    "# define iterator function, which returns frames from camera \n",
    "def source():\n",
    "    while True:\n",
    "        ret, frame = stream.read()\n",
    "        yield frame\n",
    "\n",
    "# AI prediction loop\n",
    "# Press 'x' to stop\n",
    "for res in pose_model.predict_batch(source()):\n",
    "    cv2.imshow(\"AI camera\", res.image_overlay)\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('x'):\n",
    "        break\n",
    "        \n",
    "stream.release() # release camera stream\n",
    "cv2.destroyAllWindows() # close OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6452e3f-da7e-4b76-b153-117a4a0d5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83035f-b72d-4f66-9579-6caf6852d373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17c438830f94cd2a122d5043ba79cd7154480189e06c7a17b93e87d7e528abd5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
